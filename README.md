# fun-eval
Funny eval dataset for LLM.

# Explaination
This dataset has a dozen of QA questions that I encountered difficult for top tiers LLMs to answer correctly.
The scores are generated by GPT4 that compare the generated answer and the expected keypoints, ranging from [0, 10]

# Prompt setting
 No system prompt.

# Results
